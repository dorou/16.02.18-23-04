\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{hyperref}
\numberwithin{equation}{section}
\begin{document}
\author{Ибрагимов Эрик}
\date{08.03.2018}
\title{Стоимость кодирования}
\maketitle
\newpage
\tableofcontents
\newpage
\section{12.3 Стоимость кодирования}
Метод Хаффмана позволяет строить оптимальные коды для любого рас-
пределения вероятностей, но к~сожалению не дает явной информации о
стоимости построенного кода. Поэтомудля оценки величины $C(P)$ приходится привлекать дополнительные соображения.

Пусть $P=\{p1,\dots,p_n\}$ — распределение вероятностей. Функция\footnote{Здесь и далее полагаем, что функция $x \log_2 x$ равна нулю при $x = 0$.}
\begin{equation}
H(p_1,\dots,p_n)=-\sum_{i=1}^{n}
p_i\log_{2}p_i
\end{equation}
называется энтропией распределения $P$. Нетрудно видеть, что использо-
ванная в лекции 3 для оценки биномиальных коэффициентов функция
$H(x) =-x\log_2x-(1-x)\log_2(1-x) $ является частным случаем функ-
ции $(12.3)$. В следующей теореме, доказанной Шенноном в середине 40-х
годов 20 века, энтропия используется для оценки стоимости алфавитного
кодирования.

\textbf{Теорема 12.5.} \textit{Для любого распределения вероятностей}
$\{p_1,\dots,p_n\}$
\begin{equation}
H(p_1,\dots,p_n)\le C(p_1,\dots,p_n)\le H(p_1,\dots,p_n)+1.
\end{equation}

\textsc{Доказательство. Нижняя оценка.} Покажем, что левое неравенство
(1.2) справедливо для кода Хаффмана. Сделаем это индукцией по
$n$. В основание индукции положим случай $n = 2$. Прежде всего заметим, что функция
$-x \log_2 x$ выпукла вверх при $x\in(0,1)$. Поэтому
\begin{align*}
\frac{1}{2}(-x_1\log_2x_1-x_2\log_2x_2)\le -\frac{x_1+x_2}{2}\log_2
\frac{x_1+x_2}{2}
\end{align*}
для любых $x_1, x_2 \in(0, 1)$. Следовательно,\\
\begin{align*}
H(x,1-x)=2(-x\log_2x-(1-x)\log_2(1-x))\le
-2\cdot\frac{1}{2}\log_2\frac{1}{2}=1
\end{align*}
для любого $x\in(0, 1)$. Таким образом при $n = 2$ для любого распределения вероятностей $\{p_1, p_2\}$ имеет место неравенство $H(p_1, p_2)\le 1.$ С другой стороны, очевидно, что при $n = 2$ независимо от распределения вероятностей стоимость кодирования всегда равна единице. Следовательно,
$C(p_1, p_2) \ge H(p_1, p_2).$

Теперь допустим, что нижняя оценка теоремы справедлива для любого $n$ не превосходящего $k-1$, где $k \ge 3$. Установим ее справедливость для $n= k$. Пусть $P
=\{p_1,\dots,p_k\}$ — произвольное распределение вероятностей, в~котором вероятности $p_i$ упорядочены по убыванию. Рассмотрим новое распределение $P' = \{p_1,\dots,p_{k-2}, p'_{k-1}\}$, где $p'_{k-1} =p_{k-1}+p_k.$ Распределение $P'$ возникает на первом шаге алгоритма Хаффмана, и поэтому очевидно, что\\
\begin{align*}
C(P)-C(P')=p_{k-1}l_{k-1}+p_kl_k-p'_{k-1}l'_{k-1}=
p_{k-1}+p_k.
\end{align*}
Также легко видеть, что
\begin{align*}
H(P)-H(P')=-p_{k-1}\log_2p_{k-1}-p_k\log_2p_k+p'_{k-1}\log_2p'_{k-1}.
\end{align*}
По предположению индукции $C(P')-H(P')\ge0$. Тогда
\begin{align*}
C(P)-H(P)\ge(C(P)-H(P))-(C(P')-H(P'))=\\
=(C(P)-C(P'))-(H(P)-H(P')).
\end{align*}
Следовательно,
\begin{align*}
C(P)-H(P)\ge p_{k-1}+p_k+p_{k-1}\log_2p_{k-1}+p_k\log_2p_k-p'_{k-1}\log_2p'_{k-1}=\\
=\frac{1}{2}(2p_{k-1}\log_22p_{k-1}+2p_k\log_22p_k)-p'_{k-1}\log_2p'_{k-1}\ge\\
\ge \frac{2p_{k-1}+2p_k}{2}\log_2\frac{2p_{k-1}+2p_k}{2}-p'_{k-1}\log_2p'_{k-1}=0.
\end{align*}
Нижняя оценка доказана.

\textsc{Верхняя оценка.} Пусть $P= \{p_1,\dots,p_n\}$ — произвольное распределение вероятностей, в котором вероятности $p_i$ упорядочены по убыванию. Без ограничения общности будем считать, что все вероятности положительны.\\
Так как
\begin{align*}
\sum_{i=1}^{n}2^{-(-[\log_2p_i])}\le\sum_{i=1}^{n}p_i=1,
\end{align*}
то в силутеоремы $12.2$ существует префиксный код $V=\{v_1,\dots,v_n\}$, в
котором $l(v_i)=-[\log_2p_i]$ для каждого $i\in\{1,\dots,n\}$. Такой код называется
\textit{кодом Шеннона}, и нетрудно видеть, что для его стоимости справедливо неравенство
\begin{align*}
C(p_1,\dots,p_n)=\sum_{i=1}^{n}p_i(-[\log_2p_i])\le\\
\le \sum_{i=1}^{n}p_i(-\log_2p_i+1)=H(p_1,\dots,p_n)+1.
\end{align*}
Теорема доказана.
\end{document}